<head>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=AM_CHTML"></script>
  <style>
    .references {color:red;}
    code {
      background-color: powderblue;
      white-space: pre;
    }
    .mycode{
      margin: 20px 0px 100px 10px;
      background-color: powderblue;
      width: 70%;
    }
    body{
      margin-left: 10%;
      margin-right: 10%;
    }
  </style>
</head>



<body>

<div id = 'General Kernel Estimators'>
<h1>Kernel Estimators. (Ref. [1]) </h1>
<br>
  <p>In general, a kernel estimator can be written in the following form:</p>
  <br>
  <br>
  <center>
`\hat{f(x)}=\frac{1}{n}\sum_{i=1}^{n}\frac{1}{h}\times k(\frac{x_{i}-x}{h})`</center>
  <br>
  <br>
  We could use a other choices for kernel function, one is the standard normal kernel:
  <br>
  <br>
  <center>`k(v)=\frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2}v^{2}}`</center>
  <br>
  <br>
  <p>An important theoretical result is that when as long as the following 3 conditions are satistified, the kernel in questionwill be a consistent estimator of `f(x)`.
    <br>
    <center>`(i)` `\int k(v)dv=1`</center>
    <br>
    <center>`(ii)` `k(v)=k(-v)`</center>
    <br>
    <center>`(iii)` `\int v^{2}k(v)dv=\kappa_{2}>0`</center>
  <p> By consistency, we mean that `\hat{f}(x)` converges to `f(x)` in probability. It has something to do with the bias.</p>
  <br>
  <br>
  <p> to prove consistency, we have to look at the mean square error (MSE), which defined as </p>
  <center>`[[MSE(\hat{f}(x)), \equiv, E\{[\hat{f}\left(x\right)-f\left(x\right)]^{2}\}], 
    [ , =, E[\{\hat{f}(x)\}^{2}]-\{E[\hat{f}(x)]\}^{2}+[E(\hat{f}(x))-f(x)]^{2}],
    [ , \equiv, Var(\hat{f}(x))+[bias(\hat{f}(x))]^{2}]]` </center>
 <br>
 <p>where by Taylor expansion, we have </p>
 <br>
 <center>`bias(\hat{f}(x))=\frac{h^{2}}{2}f^{(2)}(x)\int v^{2}k(v)dv+O(h^{3})`</center>
 <br>
 <p>(Notice that here, we assume that `f(x)` is 3-time differentiable, and we can weaken the condition to 2 times differentiable.)</p>
 <br>
 <p>Now the variance could be calculated as </p>
 <center>`var(\hat{f}(x))=\frac{1}{nh}\{(\int k^{2}(v)dv)\times f(x)+O(h)\}`</center>
 <p>So that</p>
 <center>`[[MSE(\hat{f}(x)), = , \frac{h^{4}}{4}[\int v^{2}k(v)dv\times f^{(2)}(x)]^{2}+\frac{\int k^{2}(v)dv}{nh}+o(h^{4}+(nh)^{-1})],
   [,,O(h^{4}+(nh)^{-1})]]`</center>
 <p>which leads to </p>
 <center>`\hat{f}(x)-f(x)=O_{p}(h^{2}+(nh)^{-1/2})=o_{p}(1)`</center>
 <br>
 <p>Now two very important remarks:</p>
 <br>
 <p>1. by choosing `h=cn^{-1/\alpha}` with `\alpha > 1`, it is ensured that we can have a consistent estimator when `n\rightarrow\infty`</p>
 <br>
 <p>2. there is an optiomal `h_{opt}=c(x)\times n^{-1/5}`, where `c(x)=\{(\int k^{2}(v)dv)\times f(x)/[\int v^{2}k(v)dv\times f^{(2)}(x)]^{2}\}^{1/5}`</p>
 <br>
 <p>Notice that this `h_{opt}` depends on `x`, which means it is a point estimator. One disadvantange of point estimator is that 
  the optimal `h` at one point may be different from the optimal `h` chosen at another point. For this reason, we also look at the 
  integrated MSE(IMSE) of \hat{f}(x).</p>
 <br>
 <center>`[[IMSE(\hat{f}), \equiv, \int E[\hat{f}(x)-f(x)]^{2}dx],
   [,=,\frac{1}{4}h^{4}(\int v^{2}k(v)dv)^{2}\int[f^{(2)}(x)]^{2}dx+\frac{\int k^{2}(v)dv}{nh}+o(h^{4}+(nh)^{-1})]]`
</center>
 <br>
 <p>Some calculus leads to `h_{opt}=c_{0}n^{-1/5}`, where 
   `c_{0}=(\int v^{2}k(v)dv)^{-2/5}\times(\int k^{2}(v)dv)^{1/5}\times\{\int[f^{(2)}(x)]^{2}dx\}^{-1/5}`</p>
 
 <br>
 <p>Now we verify the result of IMSE numerically.</p>
 <br>
 <div class = 'mycode'>
 <code>
   ## Define standard normal function
   p$kn2 <- function(x){
     value <- (1/sqrt(2*pi)) * exp(-(x^2)/2)
     return(value)
   }

   p$ka <- function(v){
     value <- ((1/sqrt(2*pi)) * exp(-(v^2)/2))^2
     return(value)
   }

   p$ka2 <- function(v){
     value <- (v^2)* (1/sqrt(2*pi)) * exp(-(v^2)/2)
     return(value)
   }

   ## The true distribution of our x is normal, with mean = 3, std = 1
   p$x <- rnorm(n = p$n, mean = 3, sd = 1)

   ## Suppose that we know the true distribution of p$x, so that we know f(x).
   ## Then we have
   p$dgp <- function(x) {
     value <- (1/sqrt(2*pi)) * (1/1) * exp(-((x-3)^2)/(2*(1^2)))
     return(value)
   }

   ## We now calculate its second derivative
   p$fpp <- 
     D(body(p$dgp)[[2]][[3]], 'x') %>% D(.,'x') # This is a call.

   ## Get the expression
   p$fpp %>% parse(text=.)

   ## evaluate fpp as a function of x.
   eval(p$fpp,list(x=1))

   ## Turn fpp into a function
   p$fppfunc <- function(x) {(eval(p$fpp))^2}

   ## verify its integral
   integrate(f = p$fppfunc, lower = -Inf, upper = Inf)

   # draw curve: curve(expr = p$fppfunc(x))

   ## Caculate each component of IMSE

   p$IMSEcomp <- list()

   p$IMSEcomp[['ka2_sq']] <- stats::integrate(f = p$ka2,
                                           lower = -Inf,
                                           upper = Inf)[[1]] %>% (function(x) {x^2})
   
   p$IMSEcomp[['ka']] <- stats::integrate(f = p$ka,
                                       lower = -Inf,
                                       upper = Inf)[[1]]

   p$IMSEcomp[['integ']] <- integrate(f = p$fppfunc, lower = -Inf, upper = Inf)[[1]]

   p$IMSE <- function(h, ka2_sq = p$IMSEcomp$ka2_sq, 
                      ka = p$IMSEcomp$ka, 
                      integ = p$IMSEcomp$integ) {
  
     value <- (1/4) * (h^4) * ka2_sq * integ + (ka)/(p$n*h)
  
     return(value)
   }

   # Draw curve
   curve(expr=p$IMSE(h), xname = 'h')

   # Draw the v = h_{opt}
   abline(v=((p$IMSEcomp$ka2_sq)^(-2/5)) * 
            ((p$IMSEcomp$ka)^(1/5)) * 
            ((p$IMSEcomp$integ)^(-1/5)) * ((p$n)^(-1/5)))
 </code>
 </div>

 
  

  
</div>
<center></center>
<center></center>
  <center></center>
<center></center><center></center>
<center></center><center></center>
<center></center><center></center>
<center></center>
  
<div class = 'references'>
  References Books:
  <br>
  [1]. Nonparametric Econometrics
  <br>
  References Sites:
  ]1[. function call, expression, function: https://stackoverflow.com/questions/8857042/r-type-conversion-expression-function
  <br>
  ]2[. eval, expression : https://stackoverflow.com/questions/1743698/evaluate-expression-given-as-a-string
  <br>
  ]3[. expression <-> function conversion: https://stackoverflow.com/questions/8857042/r-type-conversion-expression-function

</div>

</body>


<div>
  1. Math from http://asciimath.org/
  <br>
  2. Syntax of `asciimath` from https://runarberg.github.io/ascii2mathml/ 
  <br>
  3. Syntax of `asciimath` again, from https://dlippman.imathas.com/asciimathtex/AMT.html
</div>
